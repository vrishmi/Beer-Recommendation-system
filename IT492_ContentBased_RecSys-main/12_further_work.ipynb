{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation as a rating prediction/classification problem\n",
    "\n",
    "### Classification: Given the history of a user and a new beer, whether the user will give overall rating >= 4 (success) or not (failure)\n",
    "### Regression: Given the history of a user and a new beer, predict the overall rating user will give\n",
    "\n",
    "#### The approach can be be to predict/classify all aspect-ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastparquet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "all_users = pd.read_parquet(\"userFinal.parquet\")\n",
    "# all_prods = pd.read_parquet(\"prod307Final.parquet\")\n",
    "all_prods = pd.read_parquet(\"prod2549Final.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_grouped = all_users.groupby('review/profileName').sum()\n",
    "_indices = _grouped[_grouped['review/count'] >= 500].index\n",
    "newUsers = all_users[all_users['review/profileName'].isin(_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2501699, 1908)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newUsers), newUsers['review/profileName'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified splitting (per user) data into 80-20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8000027181527434"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = newUsers.groupby('review/profileName').sample(frac=0.80, replace=False)\n",
    "len(training)/len(newUsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1999972818472566"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = newUsers.drop(training.index)\n",
    "len(testing)/len(newUsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_usrdf(usr_id, sampleDF):\n",
    "    return sampleDF[sampleDF['user/Id'] == usr_id].sort_values(by='beer/id')\n",
    "def get_usr_prod_df(usrdf):\n",
    "    _flag = all_prods['beer/id'].isin(usrdf['beer/id'])\n",
    "    return all_prods[_flag]\n",
    "    \n",
    "get_A = lambda usr_prod_df: usr_prod_df.iloc[:,10:]\n",
    "get_b = lambda usrdf: usrdf.iloc[:,4] #! only overall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "def test(usr_id, regressor, verbose=True, classification = False):\n",
    "    clf = regressor\n",
    "    Test_usrdf = get_usrdf(usr_id, sampleDF=testing)\n",
    "    Test_usr_prod_df = get_usr_prod_df(Test_usrdf)\n",
    "    Test_A = get_A(Test_usr_prod_df)\n",
    "    Test_b = get_b(Test_usrdf)\n",
    "    if classification:\n",
    "        Test_b = np.where(Test_b >= 4, 1, 0)\n",
    "    score = clf.score(X=Test_A, y=Test_b)\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"[!] [Testing ] usr_id: {usr_id:^5} | Samples: {len(Test_usrdf):^5} |\"\n",
    "            f\" Parameters: {Test_A.shape[1]:^5} | Test Score: {round(score,3):>3}\", end=\"\"\n",
    "        )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_ids = newUsers['user/Id'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training `Ridge Regressor` with `5-fold cross validation` and `random search`\n",
    "#### Problem Statement: Given the history of a user and a new beer, predict the overall rating user will give"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        <==*== Fitting Ridge regressor ==*==>                                                         \n",
      "\n",
      "[!] [Training] usr_id: 16011 | Samples:  851  | Parameters: 2549  | Best Score: 0.321 | Best Param: {'alpha': 1.3885821740641209} \n",
      "[!] [Training] usr_id: 3035  | Samples: 2082  | Parameters: 2549  | Best Score: 0.238 | Best Param: {'alpha': 2.444668595146262} \n",
      "[!] [Training] usr_id: 8240  | Samples:  819  | Parameters: 2549  | Best Score: 0.324 | Best Param: {'alpha': 1.4782065008230552} \n",
      "[!] [Training] usr_id: 15603 | Samples: 6255  | Parameters: 2549  | Best Score: 0.435 | Best Param: {'alpha': 2.738984978716875} \n",
      "[!] [Training] usr_id: 7100  | Samples: 1510  | Parameters: 2549  | Best Score: 0.298 | Best Param: {'alpha': 2.001005817874194} \n"
     ]
    }
   ],
   "source": [
    "model_dict_rf = {}\n",
    "\n",
    "print(r\"<==*== Fitting Ridge regressor ==*==>\".center(150),end=\"\\n\\n\")\n",
    "\n",
    "for usr_id in usr_ids:\n",
    "    clf = RandomizedSearchCV(\n",
    "        Ridge(),\n",
    "        {\"alpha\": uniform(loc=1.1, scale=3.9)},  # uniformly pick between 1.1 and 5\n",
    "        n_iter=5,\n",
    "        cv=5,\n",
    "        verbose=0,\n",
    "    )\n",
    "    usrdf = get_usrdf(usr_id, training)\n",
    "    usr_prod_df = get_usr_prod_df(usrdf)\n",
    "    A = get_A(usr_prod_df)\n",
    "    b = get_b(usrdf)\n",
    "    print(\n",
    "        f\"[!] [Training] usr_id: {usr_id:^5} | Samples: {len(usrdf):^5} |\"\n",
    "        f\" Parameters: {A.shape[1]:^5} | \",\n",
    "        end=\"\",\n",
    "    )\n",
    "    clf.fit(A, b)\n",
    "    print(f\"Best Score: {round(clf.best_score_,3)} | Best Param: {clf.best_params_} \")\n",
    "\n",
    "    model_dict_rf[usr_id] = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] [Testing ] usr_id: 16011 | Samples:  213  | Parameters: 2549  | Test Score: 0.367 | Best Training Score: 0.321\n",
      "[!] [Testing ] usr_id: 3035  | Samples:  520  | Parameters: 2549  | Test Score: 0.245 | Best Training Score: 0.238\n",
      "[!] [Testing ] usr_id: 8240  | Samples:  205  | Parameters: 2549  | Test Score: 0.322 | Best Training Score: 0.324\n",
      "[!] [Testing ] usr_id: 15603 | Samples: 1564  | Parameters: 2549  | Test Score: 0.427 | Best Training Score: 0.435\n",
      "[!] [Testing ] usr_id: 7100  | Samples:  378  | Parameters: 2549  | Test Score: 0.248 | Best Training Score: 0.298\n"
     ]
    }
   ],
   "source": [
    "for usr_id in model_dict_rf.keys():\n",
    "    test(usr_id,regressor=model_dict_rf[usr_id], classification=False)\n",
    "    print(f\" | Best Training Score: {round(model_dict_rf[usr_id].best_score_,3):>3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training `Random Forest Classfier` with `5-fold cross validation` and `grid search`\n",
    "#### Problem Statement: Given the history of a user and a new beer, whether the user will give overall rating >= 4 (success) or not (failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    <==*== Fitting Random Forest Classifier ==*==>                                                    \n",
      "\n",
      "[!] [Training] usr_id: 16011 | Samples:  851  | Parameters: 2549  | Best Score: 0.696 | Best Param: {'min_samples_leaf': 2, 'min_samples_split': 15} \n",
      "[!] [Training] usr_id: 3035  | Samples: 2082  | Parameters: 2549  | Best Score: 0.625 | Best Param: {'min_samples_leaf': 15, 'min_samples_split': 15} \n",
      "[!] [Training] usr_id: 8240  | Samples:  819  | Parameters: 2549  | Best Score: 0.656 | Best Param: {'min_samples_leaf': 15, 'min_samples_split': 5} \n",
      "[!] [Training] usr_id: 15603 | Samples: 6255  | Parameters: 2549  | Best Score: 0.67 | Best Param: {'min_samples_leaf': 15, 'min_samples_split': 10} \n",
      "[!] [Training] usr_id: 7100  | Samples: 1510  | Parameters: 2549  | Best Score: 0.699 | Best Param: {'min_samples_leaf': 5, 'min_samples_split': 15} \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_dict_ridge = {}\n",
    "\n",
    "print(r\"<==*== Fitting Random Forest Classifier ==*==>\".center(150),end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "for usr_id in usr_ids:\n",
    "    clf = GridSearchCV(\n",
    "        RandomForestClassifier(),\n",
    "        {\"min_samples_split\": [2, 5, 10, 15], \"min_samples_leaf\": [2, 5, 10, 15]},\n",
    "        n_jobs=5,\n",
    "        cv=5,\n",
    "        verbose=0,\n",
    "    )\n",
    "    usrdf = get_usrdf(usr_id, training)\n",
    "    usr_prod_df = get_usr_prod_df(usrdf)\n",
    "    A = get_A(usr_prod_df)\n",
    "    b = np.where(get_b(usrdf)>= 4, 1, 0)\n",
    "    print(\n",
    "        f\"[!] [Training] usr_id: {usr_id:^5} | Samples: {len(usrdf):^5} |\"\n",
    "        f\" Parameters: {A.shape[1]:^5} | \",\n",
    "        end=\"\",\n",
    "    )\n",
    "    clf.fit(A, b)\n",
    "    print(f\"Best Score: {round(clf.best_score_,3):>3} | Best Param: {clf.best_params_} \")\n",
    "\n",
    "    model_dict_ridge[usr_id] = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] [Testing ] usr_id: 16011 | Samples:  213  | Parameters: 2549  | Test Score: 0.7 | Best Training Score: 0.696\n",
      "[!] [Testing ] usr_id: 3035  | Samples:  520  | Parameters: 2549  | Test Score: 0.656 | Best Training Score: 0.625\n",
      "[!] [Testing ] usr_id: 8240  | Samples:  205  | Parameters: 2549  | Test Score: 0.639 | Best Training Score: 0.656\n",
      "[!] [Testing ] usr_id: 15603 | Samples: 1564  | Parameters: 2549  | Test Score: 0.656 | Best Training Score: 0.67\n",
      "[!] [Testing ] usr_id: 7100  | Samples:  378  | Parameters: 2549  | Test Score: 0.69 | Best Training Score: 0.699\n"
     ]
    }
   ],
   "source": [
    "for usr_id in model_dict_ridge.keys():\n",
    "    test(usr_id,regressor=model_dict_ridge[usr_id], classification=True)\n",
    "    print(f\" | Best Training Score: {round(model_dict_ridge[usr_id].best_score_,3):>3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
